{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2934e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rdkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrdkit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chem\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrdkit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mChem\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AllChem, DataStructs, Descriptors\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs, Descriptors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import optuna\n",
    "\n",
    "CFG = {\n",
    "    'NBITS': 2048,\n",
    "    'SEED': 42,\n",
    "    'N_SPLITS': 5,\n",
    "    'N_TRIALS': 50 \n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['SEED'])\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    try:\n",
    "        chembl = pd.read_csv(\"data/ChEMBL_ASK1(IC50).csv\", sep=';')\n",
    "        pubchem = pd.read_csv(\"data/Pubchem_ASK1.csv\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Make sure data files are in the current directory.\")\n",
    "        return None\n",
    "\n",
    "    chembl.columns = chembl.columns.str.strip().str.replace('\"', '')\n",
    "    chembl = chembl[chembl['Standard Type'] == 'IC50']\n",
    "    chembl = chembl[['Smiles', 'Standard Value']].rename(columns={'Smiles': 'smiles', 'Standard Value': 'ic50_nM'})\n",
    "    chembl['ic50_nM'] = pd.to_numeric(chembl['ic50_nM'], errors='coerce')\n",
    "\n",
    "    pubchem = pubchem[['SMILES', 'Activity_Value']].rename(columns={'SMILES': 'smiles', 'Activity_Value': 'ic50_nM'})\n",
    "    pubchem['ic50_nM'] = pd.to_numeric(pubchem['ic50_nM'], errors='coerce')\n",
    "\n",
    "    df = pd.concat([chembl, pubchem], ignore_index=True).dropna(subset=['smiles', 'ic50_nM'])\n",
    "    df = df.drop_duplicates(subset='smiles').reset_index(drop=True)\n",
    "    df = df[df['ic50_nM'] > 0]\n",
    "\n",
    "    return df\n",
    "\n",
    "def smiles_to_fingerprint(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=CFG['NBITS'])\n",
    "        arr = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "        return arr\n",
    "    return None\n",
    "\n",
    "def calculate_rdkit_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return np.full((len(Descriptors._descList),), np.nan)\n",
    "    descriptors = [desc_func(mol) for _, desc_func in Descriptors._descList]\n",
    "    return np.array(descriptors)\n",
    "\n",
    "def IC50_to_pIC50(ic50_nM): return 9 - np.log10(ic50_nM)\n",
    "def pIC50_to_IC50(pIC50): return 10**(9 - pIC50)\n",
    "\n",
    "def get_score(y_true_ic50, y_pred_ic50, y_true_pic50, y_pred_pic50):\n",
    "    rmse = mean_squared_error(y_true_ic50, y_pred_ic50, squared=False)\n",
    "    nrmse = rmse / (np.max(y_true_ic50) - np.min(y_true_ic50))\n",
    "    A = 1 - min(nrmse, 1)\n",
    "    B = r2_score(y_true_pic50, y_pred_pic50)\n",
    "    score = 0.4 * A + 0.6 * B\n",
    "    return score\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    params = {\n",
    "        'objective': 'regression', 'metric': 'rmse', 'verbose': -1, 'n_jobs': -1,\n",
    "        'seed': CFG['SEED'], 'boosting_type': 'gbdt', 'n_estimators': 2000,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits=CFG['N_SPLITS'], shuffle=True, random_state=CFG['SEED'])\n",
    "    oof_preds = np.zeros(len(X))\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X, y):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "                  eval_metric='rmse', callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "    y_ic50_true = pIC50_to_IC50(y)\n",
    "    oof_ic50_preds = pIC50_to_IC50(oof_preds)\n",
    "    score = get_score(y_ic50_true, oof_ic50_preds, y, oof_preds)\n",
    "    return score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"1. Loading and preprocessing data...\")\n",
    "    train_df = load_and_preprocess_data()\n",
    "\n",
    "    if train_df is not None:\n",
    "        train_df['pIC50'] = IC50_to_pIC50(train_df['ic50_nM'])\n",
    "        print(\"\\n--- Feature Engineering ---\")\n",
    "        train_df['fingerprint'] = train_df['smiles'].apply(smiles_to_fingerprint)\n",
    "        train_df['descriptors'] = train_df['smiles'].apply(calculate_rdkit_descriptors)\n",
    "        train_df.dropna(subset=['fingerprint', 'descriptors'], inplace=True)\n",
    "\n",
    "        desc_stack = np.stack(train_df['descriptors'].values)\n",
    "        desc_mean = np.nanmean(desc_stack, axis=0)\n",
    "        desc_stack = np.nan_to_num(desc_stack, nan=desc_mean)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        desc_scaled = scaler.fit_transform(desc_stack)\n",
    "        fp_stack = np.stack(train_df['fingerprint'].values)\n",
    "        X = np.hstack([fp_stack, desc_scaled])\n",
    "        y = train_df['pIC50'].values\n",
    "\n",
    "        print(\"\\n--- Starting Hyperparameter Optimization with Optuna ---\")\n",
    "        study = optuna.create_study(direction='maximize', study_name='lgbm_tuning')\n",
    "        study.optimize(lambda trial: objective(trial, X, y), n_trials=CFG['N_TRIALS'])\n",
    "\n",
    "        print(f\"\\nOptimization Finished. Best Score: {study.best_value:.4f}\")\n",
    "        print(\"Best Parameters:\", study.best_params)\n",
    "\n",
    "        best_params = { 'objective': 'regression', 'metric': 'rmse', 'verbose': -1, 'n_jobs': -1,\n",
    "                        'seed': CFG['SEED'], 'boosting_type': 'gbdt', 'n_estimators': 2000 }\n",
    "        best_params.update(study.best_params)\n",
    "\n",
    "        print(\"\\n--- Training Final Model with Best Parameters ---\")\n",
    "        test_df = pd.read_csv(\"./test.csv\")\n",
    "        test_df['fingerprint'] = test_df['Smiles'].apply(smiles_to_fingerprint)\n",
    "        test_df['descriptors'] = test_df['Smiles'].apply(calculate_rdkit_descriptors)\n",
    "\n",
    "        valid_test_mask = test_df['fingerprint'].notna() & test_df['descriptors'].notna()\n",
    "        fp_test_stack = np.stack(test_df.loc[valid_test_mask, 'fingerprint'].values)\n",
    "        desc_test_stack = np.stack(test_df.loc[valid_test_mask, 'descriptors'].values)\n",
    "        desc_test_stack = np.nan_to_num(desc_test_stack, nan=desc_mean)\n",
    "        desc_test_scaled = scaler.transform(desc_test_stack)\n",
    "        X_test = np.hstack([fp_test_stack, desc_test_scaled])\n",
    "\n",
    "        kf = KFold(n_splits=CFG['N_SPLITS'], shuffle=True, random_state=CFG['SEED'])\n",
    "        test_preds = np.zeros(len(X_test))\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "            print(f\"--- Training Fold {fold+1}/{CFG['N_SPLITS']} ---\")\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            model = lgb.LGBMRegressor(**best_params)\n",
    "            model.fit(X_train, y_train)\n",
    "            test_preds += model.predict(X_test) / CFG['N_SPLITS']\n",
    "\n",
    "        print(\"\\n3. Generating submission file...\")\n",
    "        submission_df = pd.read_csv(\"./sample_submission.csv\")\n",
    "        pred_df = pd.DataFrame({'ID': test_df.loc[valid_test_mask, 'ID'], 'ASK1_IC50_nM': pIC50_to_IC50(test_preds)})\n",
    "        submission_df = submission_df[['ID']].merge(pred_df, on='ID', how='left')\n",
    "        submission_df['ASK1_IC50_nM'].fillna(train_df['ic50_nM'].mean(), inplace=True)\n",
    "        submission_df.to_csv(\"lgbm_tuned_submission.csv\", index=False)\n",
    "        print(\"Submission file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456519cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
